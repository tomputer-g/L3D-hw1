{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673a294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from starter.utils import get_device, get_mesh_renderer, load_cow_mesh, get_points_renderer, unproject_depth_image\n",
    "from starter.render_generic import load_rgbd_data\n",
    "import mcubes\n",
    "import pytorch3d\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f114097",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e5d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(images_list: list[np.ndarray], gif_path: Path, FPS=15):\n",
    "    # images_list is a list of (H,W,3) images\n",
    "    assert images_list[0].shape[2] == 3\n",
    "    \n",
    "    frame_duration_ms = 1000 // FPS\n",
    "    imageio.mimsave(gif_path, images_list, duration=frame_duration_ms, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f8146",
   "metadata": {},
   "source": [
    "## Question 1: Practicing with Cameras\n",
    "\n",
    "### 1.1: 360-deg renders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d970c8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering cow...: 100%|██████████| 36/36 [00:00<00:00, 70.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = get_device()\n",
    "cow_path = \"data/cow.obj\"\n",
    "image_size=256\n",
    "\n",
    "# Get the renderer.\n",
    "renderer = get_mesh_renderer(image_size=image_size)\n",
    "\n",
    "# Get the vertices, faces, and textures.\n",
    "vertices, faces = load_cow_mesh(cow_path)\n",
    "vertices = vertices.unsqueeze(0)  # (N_v, 3) -> (1, N_v, 3)\n",
    "faces = faces.unsqueeze(0)  # (N_f, 3) -> (1, N_f, 3)\n",
    "textures = torch.ones_like(vertices)  # (1, N_v, 3)\n",
    "textures = textures * torch.tensor([0.7, 0.7, 1])  # (1, N_v, 3)\n",
    "\n",
    "mesh = pytorch3d.structures.Meshes(\n",
    "    verts=vertices,\n",
    "    faces=faces,\n",
    "    textures=pytorch3d.renderer.TexturesVertex(textures),\n",
    ")\n",
    "mesh = mesh.to(device)\n",
    "\n",
    "\n",
    "# Place a point light in front of the cow.\n",
    "lights = pytorch3d.renderer.PointLights(location=[[0, 0, -3]], device=device)\n",
    "\n",
    "images_list = []\n",
    "\n",
    "for i in tqdm(range(0,360,10), desc=\"Rendering cow...\"):\n",
    "\n",
    "    theta = np.radians(i)\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    R = torch.tensor([[c, 0, s], [0, 1, 0], [-s, 0, c]]).unsqueeze(0)\n",
    "\n",
    "    # Prepare the camera:\n",
    "    cameras = pytorch3d.renderer.FoVPerspectiveCameras(\n",
    "        R=R, T=torch.tensor([[0, 0, 3]]), fov=60, device=device\n",
    "    )\n",
    "    \n",
    "    rend = renderer(mesh, cameras=cameras, lights=lights)\n",
    "    img = rend.cpu().numpy()[0, ..., :3]\n",
    "        \n",
    "    img *= 255\n",
    "    img = img.astype('uint8')\n",
    "    images_list.append(img)\n",
    "\n",
    "create_gif(images_list, Path('out.gif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f096e",
   "metadata": {},
   "source": [
    "## HW1Q1 result\n",
    "<img src=\"out.gif\" width=\"256\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d189bce",
   "metadata": {},
   "source": [
    "## 1.2: Dolly Zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19551fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_12044/910618457.py:19: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  distance = width / (2 * np.tan(0.5 * np.radians(fov))) # TODO: change this.\n",
      "100%|██████████| 10/10 [00:00<00:00, 177.39it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_size=256\n",
    "num_frames=10\n",
    "duration=3\n",
    "output_file=\"output/dolly.gif\"\n",
    "device = get_device()\n",
    "\n",
    "mesh = pytorch3d.io.load_objs_as_meshes([\"data/cow_on_plane.obj\"])\n",
    "mesh = mesh.to(device)\n",
    "renderer = get_mesh_renderer(image_size=image_size, device=device)\n",
    "lights = pytorch3d.renderer.PointLights(location=[[0.0, 0.0, -3.0]], device=device)\n",
    "\n",
    "fovs = torch.linspace(5, 120, num_frames)\n",
    "\n",
    "renders = []\n",
    "\n",
    "width = 5\n",
    "for fov in tqdm(fovs):\n",
    "    # distance = 50\n",
    "    distance = width / (2 * np.tan(0.5 * np.radians(fov))) # TODO: change this.\n",
    "    T = [[0, 0, distance]]  # TODO: Change this.\n",
    "    cameras = pytorch3d.renderer.FoVPerspectiveCameras(fov=fov, T=T, device=device)\n",
    "    rend = renderer(mesh, cameras=cameras, lights=lights)\n",
    "    rend = rend[0, ..., :3].cpu().numpy()  # (N, H, W, 3)\n",
    "    renders.append(rend)\n",
    "\n",
    "images = []\n",
    "for i, r in enumerate(renders):\n",
    "    image = Image.fromarray((r * 255).astype(np.uint8))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.text((20, 20), f\"fov: {fovs[i]:.2f}\", fill=(255, 0, 0))\n",
    "    images.append(np.array(image))\n",
    "\n",
    "create_gif(images, Path('hw1q1p2.gif'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc4addf",
   "metadata": {},
   "source": [
    "## q1.2 Dolly Zoom Result\n",
    "<img src=\"hw1q1p2.gif\" width=\"256\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647468ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
